{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf2066e7",
   "metadata": {},
   "source": [
    "# Creating the Reddit Network of Climate Discussion Contributors \n",
    "\n",
    "Using the pre-trained Climate Change Sentiment classifier on submissions and comments from Redittors, we model a network of Redittors being pro, neutral or anti to Climate Change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dceab9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import time, datetime\n",
    "\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from nltk import word_tokenize, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f59c6c",
   "metadata": {},
   "source": [
    "## 1) Load Reddit data\n",
    "\n",
    "Initially, the data extracted from Reddit is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8986b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATA_DIR = Path(os.getcwd()).parent / 'data'\n",
    "#DATA_DIR = Path('/work3/s194253')\n",
    "\n",
    "# year\n",
    "year = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb3af1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 27.186524868011475 seconds to load dataframe...\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# load data\n",
    "comments = pd.read_json(DATA_DIR / f'{year}/comments90k_opinion_{year}.json.bz2')\n",
    "submissions = pd.read_json(DATA_DIR / f'{year}/submissions_opinion_{year}.json.bz2')\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Took {end-start} seconds to load dataframe...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5641383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135946, 17)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a50e49cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238433, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606cdf81",
   "metadata": {},
   "source": [
    "## 2) Link comment authors to submission authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "497e0a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionaries\n",
    "comment_authors = dict(zip(comments.id, comments.author))\n",
    "parent = dict(zip(comments.id, comments.parent_id))\n",
    "submission_authors = dict(zip(submissions.id, submissions.author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "726f60c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parent_author(comment_id, comment_authors=comment_authors, parent=parent, submission_authors=submission_authors):\n",
    "    '''Links the comment id to the author of its parent.\n",
    "    \n",
    "    input: comment_id\n",
    "    returns: author'''\n",
    "    \n",
    "    parent_id = parent[comment_id]\n",
    "    \n",
    "    try: # try to look for the parent_id key\n",
    "        if parent_id[:3] == 't1_':\n",
    "            return comment_authors[parent_id[3:]]\n",
    "        if parent_id[:3] == 't3_':\n",
    "            return submission_authors[parent_id[3:]]    \n",
    "    except KeyError: # if parent_id was not extracted in comments or submissions\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe111ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['parent_author'] = comments['id'].apply(lambda x: parent_author(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b3d6706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of IDs that could not be extracted: 387/238433 = 0.0016\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of IDs that could not be extracted: {comments['parent_author'].isnull().sum()}/{comments['parent_author'].__len__()} = {comments['parent_author'].isnull().sum() / comments['parent_author'].__len__() :.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caf1b921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238046, 17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove NaN parent authors\n",
    "comments = comments[-comments.parent_author.isnull()].reset_index(drop=True)\n",
    "\n",
    "# size of data\n",
    "comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe37f0dd",
   "metadata": {},
   "source": [
    "## 3) Filter the Reddit comments and submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "979e002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join title and selftext to text attribute in submissions\n",
    "submissions['text'] = submissions.title + \" \" + submissions.selftext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17c1b138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN values for awarders by setting it to 0 or empty list\n",
    "submissions['all_awardings'] = submissions['all_awardings'].fillna(\"\").apply(list)\n",
    "submissions['awarders'] = submissions['awarders'].fillna(\"\").apply(list)\n",
    "submissions['total_awards_received'] = submissions['total_awards_received'].fillna(0)\n",
    "\n",
    "comments['all_awardings'] = comments['all_awardings'].fillna(\"\").apply(list)\n",
    "comments['total_awards_received'] = comments['total_awards_received'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02dfe98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of deleted users: 8501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(229545, 17)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter comments and remove rows with deleted users\n",
    "filtered_comments = comments\n",
    "\n",
    "deleted_users_idx = np.logical_or(filtered_comments.author == '[deleted]', filtered_comments.parent_author == '[deleted]')\n",
    "filtered_comments = filtered_comments[-deleted_users_idx]\n",
    "print(f\"Number of deleted users: {deleted_users_idx.sum()}\")\n",
    "\n",
    "# update index\n",
    "filtered_comments.reset_index(drop=True, inplace=True)\n",
    "filtered_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4585709f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of deleted users: 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(135846, 17)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter submissions and remove rows with deleted users\n",
    "filtered_submissions = submissions\n",
    "\n",
    "deleted_users_idx = filtered_submissions.author == '[deleted]'\n",
    "filtered_submissions = filtered_submissions[-deleted_users_idx]\n",
    "print(f\"Number of deleted users: {deleted_users_idx.sum()}\")\n",
    "\n",
    "# update index\n",
    "filtered_submissions.reset_index(drop=True, inplace=True)\n",
    "filtered_submissions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffa0af05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-80f9f497bc8c>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_submissions['opinion_score'] = filtered_submissions.opinion.apply(lambda x: op_dict[x])\n",
      "<ipython-input-15-80f9f497bc8c>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_comments['opinion_score'] = filtered_comments.opinion.apply(lambda x: op_dict[x])\n"
     ]
    }
   ],
   "source": [
    "op_dict = {'News': 0,\n",
    "          'Neutral': 0,\n",
    "          'Pro': 1,\n",
    "          'Anti': -1}\n",
    "\n",
    "filtered_submissions['opinion_score'] = filtered_submissions.opinion.apply(lambda x: op_dict[x])\n",
    "filtered_comments['opinion_score'] = filtered_comments.opinion.apply(lambda x: op_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d00e98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>awarders</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>year</th>\n",
       "      <th>opinion</th>\n",
       "      <th>opinion_probs</th>\n",
       "      <th>opinion_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abdopc</td>\n",
       "      <td>-en-</td>\n",
       "      <td>@washingtonpost: Extreme weather in 2018 was a...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>newsbotbot</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>@washingtonpost: Extreme weather in 2018 was a...</td>\n",
       "      <td>{'washingtonpost': 1, 'extrem': 1, 'weather': ...</td>\n",
       "      <td>washingtonpost extrem weather rage howl signal...</td>\n",
       "      <td>2019</td>\n",
       "      <td>News</td>\n",
       "      <td>[0.1275265063, 0.12615991340000002, 0.54378136...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abdn8t</td>\n",
       "      <td>Ama98</td>\n",
       "      <td>Predictions about the next year</td>\n",
       "      <td>The wall will never get funding, instead Trump...</td>\n",
       "      <td>1</td>\n",
       "      <td>ChapoTrapHouse</td>\n",
       "      <td>15</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Predictions about the next year The wall will ...</td>\n",
       "      <td>{'predict': 1, 'next': 1, 'year': 1, 'wall': 1...</td>\n",
       "      <td>predict next year wall never get fund instead ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[0.14072116540000001, 0.6952812997000001, 0.04...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abdjq5</td>\n",
       "      <td>hjbarraza</td>\n",
       "      <td>The Story of 2018 Was Climate Change</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>climate</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>The Story of 2018 Was Climate Change</td>\n",
       "      <td>{'stori': 1, 'climat': 1, 'chang': 1}</td>\n",
       "      <td>stori climat chang</td>\n",
       "      <td>2019</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[0.14858327670000002, 0.5444978271, 0.12987582...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abdhf9</td>\n",
       "      <td>EcoInternetNewsfeed</td>\n",
       "      <td>Galapagos, Evolution &amp;amp; Climate Change: Tra...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>climate</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Galapagos, Evolution &amp;amp; Climate Change: Tra...</td>\n",
       "      <td>{'galapago': 1, 'evolut': 1, 'amp': 2, 'climat...</td>\n",
       "      <td>galapago evolut amp climat chang travel book r...</td>\n",
       "      <td>2019</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[0.0664715475, 0.3567104474, 0.2596014974, 0.3...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abdh4b</td>\n",
       "      <td>EcoInternetNewsfeed</td>\n",
       "      <td>Galapagos, Evolution &amp;amp; Climate Change: Tra...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>EcoInternet</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Galapagos, Evolution &amp;amp; Climate Change: Tra...</td>\n",
       "      <td>{'galapago': 1, 'evolut': 1, 'amp': 2, 'climat...</td>\n",
       "      <td>galapago evolut amp climat chang travel book r...</td>\n",
       "      <td>2019</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[0.0664715475, 0.3567104474, 0.2596014974, 0.3...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id               author  \\\n",
       "0  abdopc                 -en-   \n",
       "1  abdn8t                Ama98   \n",
       "2  abdjq5            hjbarraza   \n",
       "3  abdhf9  EcoInternetNewsfeed   \n",
       "4  abdh4b  EcoInternetNewsfeed   \n",
       "\n",
       "                                               title  \\\n",
       "0  @washingtonpost: Extreme weather in 2018 was a...   \n",
       "1                    Predictions about the next year   \n",
       "2               The Story of 2018 Was Climate Change   \n",
       "3  Galapagos, Evolution &amp; Climate Change: Tra...   \n",
       "4  Galapagos, Evolution &amp; Climate Change: Tra...   \n",
       "\n",
       "                                            selftext  score       subreddit  \\\n",
       "0                                                         1      newsbotbot   \n",
       "1  The wall will never get funding, instead Trump...      1  ChapoTrapHouse   \n",
       "2                                                         1         climate   \n",
       "3                                                         1         climate   \n",
       "4                                                         1     EcoInternet   \n",
       "\n",
       "   num_comments all_awardings awarders  total_awards_received       date  \\\n",
       "0             0            []       []                    0.0 2019-01-01   \n",
       "1            15            []       []                    0.0 2019-01-01   \n",
       "2             0            []       []                    0.0 2019-01-01   \n",
       "3             0            []       []                    0.0 2019-01-01   \n",
       "4             0            []       []                    0.0 2019-01-01   \n",
       "\n",
       "                                                text  \\\n",
       "0  @washingtonpost: Extreme weather in 2018 was a...   \n",
       "1  Predictions about the next year The wall will ...   \n",
       "2              The Story of 2018 Was Climate Change    \n",
       "3  Galapagos, Evolution &amp; Climate Change: Tra...   \n",
       "4  Galapagos, Evolution &amp; Climate Change: Tra...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  {'washingtonpost': 1, 'extrem': 1, 'weather': ...   \n",
       "1  {'predict': 1, 'next': 1, 'year': 1, 'wall': 1...   \n",
       "2              {'stori': 1, 'climat': 1, 'chang': 1}   \n",
       "3  {'galapago': 1, 'evolut': 1, 'amp': 2, 'climat...   \n",
       "4  {'galapago': 1, 'evolut': 1, 'amp': 2, 'climat...   \n",
       "\n",
       "                                      processed_text  year  opinion  \\\n",
       "0  washingtonpost extrem weather rage howl signal...  2019     News   \n",
       "1  predict next year wall never get fund instead ...  2019  Neutral   \n",
       "2                                 stori climat chang  2019  Neutral   \n",
       "3  galapago evolut amp climat chang travel book r...  2019  Neutral   \n",
       "4  galapago evolut amp climat chang travel book r...  2019  Neutral   \n",
       "\n",
       "                                       opinion_probs  opinion_score  \n",
       "0  [0.1275265063, 0.12615991340000002, 0.54378136...              0  \n",
       "1  [0.14072116540000001, 0.6952812997000001, 0.04...              0  \n",
       "2  [0.14858327670000002, 0.5444978271, 0.12987582...              0  \n",
       "3  [0.0664715475, 0.3567104474, 0.2596014974, 0.3...              0  \n",
       "4  [0.0664715475, 0.3567104474, 0.2596014974, 0.3...              0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_submissions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5e6e12",
   "metadata": {},
   "source": [
    "## 4) Handle author metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74bc6f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(df, reddit_type='comment'):\n",
    "    \n",
    "    author_df = pd.DataFrame()\n",
    "    \n",
    "    groups = df.groupby(by='author')\n",
    "\n",
    "    author_df['text'] = groups.text.apply(lambda x: list(x))\n",
    "    author_df['all_awardings'] = groups.all_awardings.apply(lambda x: np.concatenate([*x]))\n",
    "    author_df['total_awards_received'] = groups.total_awards_received.sum()\n",
    "    author_df['total_awards_received'] = groups.total_awards_received.sum()\n",
    "    author_df['score'] = groups.score.sum()\n",
    "    author_df[f'first_{reddit_type}'] = groups.date.apply(lambda x: x.sort_values(ascending=True).iloc[0].timestamp())\n",
    "    author_df[f'last_{reddit_type}'] = groups.date.apply(lambda x: x.sort_values(ascending=True).iloc[-1].timestamp())\n",
    "    author_df[f'num_{reddit_type}s'] = groups.apply(lambda x: x.__len__())\n",
    "    author_df['opinion_score'] = groups.opinion_score.mean()\n",
    "    \n",
    "    if reddit_type == 'comment':\n",
    "        author_df['controversiality'] = groups.controversiality.sum()\n",
    "    \n",
    "    return author_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f68fe633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting metadata for comments...\n",
      "\n",
      "Extracting metadata for submissions...\n"
     ]
    }
   ],
   "source": [
    "#extract metadata\n",
    "print(\"Extracting metadata for comments...\")\n",
    "author_comment = get_metadata(filtered_comments, reddit_type='comment')\n",
    "\n",
    "print(\"\\nExtracting metadata for submissions...\")\n",
    "author_submission = get_metadata(filtered_submissions, reddit_type='submission')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3842948",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_joined = author_comment.join(author_submission, on='author', lsuffix='_c', rsuffix='_s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db6a3838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "Successfully combined dataframe!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>score</th>\n",
       "      <th>opinion_score</th>\n",
       "      <th>first_comment</th>\n",
       "      <th>last_comment</th>\n",
       "      <th>first_submission</th>\n",
       "      <th>last_submission</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>num_submissions</th>\n",
       "      <th>comment_controversiality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Crazypenguin314</th>\n",
       "      <td>You’re right, but it’s about the message. Nobo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.552608e+09</td>\n",
       "      <td>1.552608e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>killcats</th>\n",
       "      <td>Twice</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.568074e+09</td>\n",
       "      <td>1.568074e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theghostofQEII</th>\n",
       "      <td>At this point we have to figure out how to geo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1.568938e+09</td>\n",
       "      <td>1.571875e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>illiberation</th>\n",
       "      <td>I think he's more or less alluding to the idea...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>1.572739e+09</td>\n",
       "      <td>1.572739e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gross_burrito</th>\n",
       "      <td>lmaoo If only it was that bad</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.566691e+09</td>\n",
       "      <td>1.566691e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hachiman</th>\n",
       "      <td>She's cut from the same garbage cloth he is. H...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.576282e+09</td>\n",
       "      <td>1.576282e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DGDownUnder</th>\n",
       "      <td>Combating Climate Change The Socialism Way  Oh...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.568938e+09</td>\n",
       "      <td>1.568938e+09</td>\n",
       "      <td>1.567728e+09</td>\n",
       "      <td>1.568938e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timetobehappy</th>\n",
       "      <td>((Hugs)) vent away.</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.577232e+09</td>\n",
       "      <td>1.577232e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acb1971</th>\n",
       "      <td>Be best, Melania!</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.576282e+09</td>\n",
       "      <td>1.576282e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mj1127</th>\n",
       "      <td>Revolution is nice because it covers heartworm...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1.557360e+09</td>\n",
       "      <td>1.557446e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              text  \\\n",
       "author                                                               \n",
       "Crazypenguin314  You’re right, but it’s about the message. Nobo...   \n",
       "killcats                                                     Twice   \n",
       "theghostofQEII   At this point we have to figure out how to geo...   \n",
       "illiberation     I think he's more or less alluding to the idea...   \n",
       "gross_burrito                        lmaoo If only it was that bad   \n",
       "hachiman         She's cut from the same garbage cloth he is. H...   \n",
       "DGDownUnder      Combating Climate Change The Socialism Way  Oh...   \n",
       "timetobehappy                                  ((Hugs)) vent away.   \n",
       "acb1971                                          Be best, Melania!   \n",
       "mj1127           Revolution is nice because it covers heartworm...   \n",
       "\n",
       "                all_awardings  total_awards_received  score  opinion_score  \\\n",
       "author                                                                       \n",
       "Crazypenguin314            []                    0.0    1.0           0.00   \n",
       "killcats                   []                    0.0    1.0           0.00   \n",
       "theghostofQEII             []                    0.0    2.0          -0.25   \n",
       "illiberation               []                    0.0   -1.0          -0.50   \n",
       "gross_burrito              []                    0.0    1.0           0.00   \n",
       "hachiman                   []                    0.0    1.0           0.00   \n",
       "DGDownUnder                []                    0.0  179.0           0.25   \n",
       "timetobehappy              []                    0.0    1.0           0.00   \n",
       "acb1971                    []                    0.0    1.0           0.00   \n",
       "mj1127                     []                    0.0    3.0          -0.25   \n",
       "\n",
       "                 first_comment  last_comment  first_submission  \\\n",
       "author                                                           \n",
       "Crazypenguin314   1.552608e+09  1.552608e+09               NaN   \n",
       "killcats          1.568074e+09  1.568074e+09               NaN   \n",
       "theghostofQEII    1.568938e+09  1.571875e+09               NaN   \n",
       "illiberation      1.572739e+09  1.572739e+09               NaN   \n",
       "gross_burrito     1.566691e+09  1.566691e+09               NaN   \n",
       "hachiman          1.576282e+09  1.576282e+09               NaN   \n",
       "DGDownUnder       1.568938e+09  1.568938e+09      1.567728e+09   \n",
       "timetobehappy     1.577232e+09  1.577232e+09               NaN   \n",
       "acb1971           1.576282e+09  1.576282e+09               NaN   \n",
       "mj1127            1.557360e+09  1.557446e+09               NaN   \n",
       "\n",
       "                 last_submission  num_comments  num_submissions  \\\n",
       "author                                                            \n",
       "Crazypenguin314              NaN             1              NaN   \n",
       "killcats                     NaN             1              NaN   \n",
       "theghostofQEII               NaN             2              NaN   \n",
       "illiberation                 NaN             1              NaN   \n",
       "gross_burrito                NaN             1              NaN   \n",
       "hachiman                     NaN             1              NaN   \n",
       "DGDownUnder         1.568938e+09             1              4.0   \n",
       "timetobehappy                NaN             1              NaN   \n",
       "acb1971                      NaN             1              NaN   \n",
       "mj1127                       NaN             2              NaN   \n",
       "\n",
       "                 comment_controversiality  \n",
       "author                                     \n",
       "Crazypenguin314                       0.0  \n",
       "killcats                              0.0  \n",
       "theghostofQEII                        0.0  \n",
       "illiberation                          0.0  \n",
       "gross_burrito                         0.0  \n",
       "hachiman                              0.0  \n",
       "DGDownUnder                           0.0  \n",
       "timetobehappy                         0.0  \n",
       "acb1971                               0.0  \n",
       "mj1127                                0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author = pd.DataFrame()\n",
    "print(\"Running...\")\n",
    "for attr, fill in {'text': 'list', 'all_awardings': 'list', 'total_awards_received': 'num', 'score': 'num', 'opinion_score':'num'}.items():\n",
    "    for letter in ['s', 'c']:\n",
    "        \n",
    "        # reformat rows\n",
    "        if fill == 'list':\n",
    "            author_joined[f'{attr}_{letter}'] = author_joined[f'{attr}_{letter}'].fillna(\"\").apply(list)\n",
    "        elif fill == 'num':\n",
    "            author_joined[f'{attr}_{letter}'] = author_joined[f'{attr}_{letter}'].fillna(0)\n",
    "            \n",
    "    # create combined dataframe\n",
    "    author[f'{attr}'] = author_joined[f'{attr}_s'] + author_joined[f'{attr}_c']\n",
    "    if attr == 'opinion_score':\n",
    "        author[f'{attr}'] /= 2\n",
    "    \n",
    "print(\"Successfully combined dataframe!\")\n",
    "\n",
    "# keep relevant attributes\n",
    "aoi = ['first_comment', 'last_comment', \n",
    "       'first_submission', 'last_submission', \n",
    "       'num_comments', 'num_submissions',  \n",
    "       'controversiality']\n",
    "author[aoi] = author_joined[aoi]\n",
    "\n",
    "# modify list of texts to one large string\n",
    "author['text'] = author['text'].apply(lambda x: ' '.join(str(v) for v in x))\n",
    "\n",
    "# rename\n",
    "author = author.rename(columns={'controversiality':'comment_controversiality'})\n",
    "author.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21deb5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stop-words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# add webpages to stopwords\n",
    "stop_words.add('http') \n",
    "stop_words.add('https')\n",
    "\n",
    "# Preprocess the text \n",
    "porter = PorterStemmer()\n",
    "exclusions = {'RT'}\n",
    "\n",
    "# define tokenizing function\n",
    "clean = lambda x: Counter([porter.stem(word_token).lower() for word_token in word_tokenize(x) \\\n",
    "                       if word_token.lower() not in stop_words \\\n",
    "                       and word_token.isalpha() \\\n",
    "                       and word_token not in exclusions])\n",
    "\n",
    "# apply tokenizing to texts - apply for seeing progress bar WHEN running\n",
    "tokens = author['text'].apply(lambda text: clean(text))\n",
    "author['tokens'] = tokens\n",
    "\n",
    "# join tokens to one string\n",
    "author['processed_text'] = author['tokens'].apply(lambda x: ' '.join(str(v) for v in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c6c0ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "author.to_json(DATA_DIR / f'author_opinion_{year}.json.bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac22d7c",
   "metadata": {},
   "source": [
    "## 5) Create ClimateGraph from edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c7d64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "author = pd.read_json(DATA_DIR / f'author_opinion_{year}.json.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8969247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>score</th>\n",
       "      <th>opinion_score</th>\n",
       "      <th>first_comment</th>\n",
       "      <th>last_comment</th>\n",
       "      <th>first_submission</th>\n",
       "      <th>last_submission</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>num_submissions</th>\n",
       "      <th>comment_controversiality</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zombieslayer287</th>\n",
       "      <td>So hard life &amp;gt;&amp;gt;&amp;gt; no life/ not exist a...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1575244800</td>\n",
       "      <td>1575244800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hard': 1, 'life': 1, 'gt': 3, 'exist': 1, 'w...</td>\n",
       "      <td>hard life gt exist wrong selfish idiot yike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ThePittyInTheKitty</th>\n",
       "      <td>http://www.olcv.org/\\nCall. Call. Call.</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1561420800</td>\n",
       "      <td>1561420800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'call': 3}</td>\n",
       "      <td>call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrownUpTurk</th>\n",
       "      <td>Technically not wrong to have less kids when o...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1566518400</td>\n",
       "      <td>1566518400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'technic': 1, 'wrong': 1, 'less': 2, 'kid': 3...</td>\n",
       "      <td>technic wrong less kid averag cost brought hom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KingKooooZ</th>\n",
       "      <td>Link? So... she got divorced from Ted Turner, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1572048000</td>\n",
       "      <td>1572048000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'link': 1, 'got': 1, 'divorc': 1, 'ted': 1, '...</td>\n",
       "      <td>link got divorc ted turner cocreat captain planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self_saucing</th>\n",
       "      <td>September 20 :)</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1568505600</td>\n",
       "      <td>1568505600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'septemb': 1}</td>\n",
       "      <td>septemb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text  \\\n",
       "zombieslayer287     So hard life &gt;&gt;&gt; no life/ not exist a...   \n",
       "ThePittyInTheKitty            http://www.olcv.org/\\nCall. Call. Call.   \n",
       "GrownUpTurk         Technically not wrong to have less kids when o...   \n",
       "KingKooooZ          Link? So... she got divorced from Ted Turner, ...   \n",
       "self_saucing                                          September 20 :)   \n",
       "\n",
       "                   all_awardings  total_awards_received  score  opinion_score  \\\n",
       "zombieslayer287               []                      0      2          -0.25   \n",
       "ThePittyInTheKitty            []                      0      1           0.00   \n",
       "GrownUpTurk                   []                      0      1           0.00   \n",
       "KingKooooZ                    []                      0      2           0.00   \n",
       "self_saucing                  []                      0      1           0.00   \n",
       "\n",
       "                    first_comment  last_comment  first_submission  \\\n",
       "zombieslayer287        1575244800    1575244800               NaN   \n",
       "ThePittyInTheKitty     1561420800    1561420800               NaN   \n",
       "GrownUpTurk            1566518400    1566518400               NaN   \n",
       "KingKooooZ             1572048000    1572048000               NaN   \n",
       "self_saucing           1568505600    1568505600               NaN   \n",
       "\n",
       "                    last_submission  num_comments  num_submissions  \\\n",
       "zombieslayer287                 NaN             2              NaN   \n",
       "ThePittyInTheKitty              NaN             1              NaN   \n",
       "GrownUpTurk                     NaN             1              NaN   \n",
       "KingKooooZ                      NaN             2              NaN   \n",
       "self_saucing                    NaN             1              NaN   \n",
       "\n",
       "                    comment_controversiality  \\\n",
       "zombieslayer287                            0   \n",
       "ThePittyInTheKitty                         0   \n",
       "GrownUpTurk                                0   \n",
       "KingKooooZ                                 0   \n",
       "self_saucing                               0   \n",
       "\n",
       "                                                               tokens  \\\n",
       "zombieslayer287     {'hard': 1, 'life': 1, 'gt': 3, 'exist': 1, 'w...   \n",
       "ThePittyInTheKitty                                        {'call': 3}   \n",
       "GrownUpTurk         {'technic': 1, 'wrong': 1, 'less': 2, 'kid': 3...   \n",
       "KingKooooZ          {'link': 1, 'got': 1, 'divorc': 1, 'ted': 1, '...   \n",
       "self_saucing                                           {'septemb': 1}   \n",
       "\n",
       "                                                       processed_text  \n",
       "zombieslayer287           hard life gt exist wrong selfish idiot yike  \n",
       "ThePittyInTheKitty                                               call  \n",
       "GrownUpTurk         technic wrong less kid averag cost brought hom...  \n",
       "KingKooooZ          link got divorc ted turner cocreat captain planet  \n",
       "self_saucing                                                  septemb  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea94826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the weighted edgelist by counting - using score as a randomly picked attributed to obtain a single pd.Series\n",
    "weighted_edgelist = filtered_comments.groupby(by=['author', 'parent_author']).count().score\n",
    "weighted_edgelist = weighted_edgelist.reset_index().rename(columns={'score':'weight'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae243899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>parent_author</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131178</th>\n",
       "      <td>hauska_juoppo</td>\n",
       "      <td>mvea</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>1norcal415</td>\n",
       "      <td>deadfisher</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137591</th>\n",
       "      <td>joeydsa</td>\n",
       "      <td>MrLongWalk</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142827</th>\n",
       "      <td>lizzieroarden</td>\n",
       "      <td>hrimfaxi_work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63132</th>\n",
       "      <td>Nefertirri</td>\n",
       "      <td>AlwaysHangry12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author   parent_author  weight\n",
       "131178  hauska_juoppo            mvea       1\n",
       "1260       1norcal415      deadfisher       1\n",
       "137591        joeydsa      MrLongWalk       2\n",
       "142827  lizzieroarden   hrimfaxi_work       1\n",
       "63132      Nefertirri  AlwaysHangry12       1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_edgelist.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58024aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat weighted edgelist to 3-tuples\n",
    "edgelist = list(zip(weighted_edgelist.author, weighted_edgelist.parent_author, weighted_edgelist.weight))\n",
    "\n",
    "# construct graph\n",
    "ClimateGraph = nx.DiGraph()\n",
    "ClimateGraph.add_weighted_edges_from(edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40a56cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weight of edge of first link\n",
    "ClimateGraph.get_edge_data('redwolf177', 'TheNoHeart')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931deb60",
   "metadata": {},
   "source": [
    "## 6) Add node attributes to ClimateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05df161b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80530214df6b4d5c90ee5ffd1ca21ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for redditor in tqdm(author.index):\n",
    "    meta = {redditor: author.loc[redditor].to_dict()}\n",
    "    nx.set_node_attributes(ClimateGraph, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0c3a8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean graph\n",
    "ClimateGraph.remove_edges_from(nx.selfloop_edges(ClimateGraph))\n",
    "\n",
    "# remove nodes that do not have metadata\n",
    "remove_nodes = []\n",
    "for k, v in ClimateGraph.nodes(data=True):\n",
    "    try: \n",
    "        check = v['opinion_score']\n",
    "    except KeyError:\n",
    "        remove_nodes.append(k)\n",
    "\n",
    "ClimateGraph.remove_nodes_from(remove_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72736157",
   "metadata": {},
   "source": [
    "## 5) Save ClimateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f697291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save graph as json\n",
    "from networkx.readwrite import json_graph\n",
    "import json\n",
    "\n",
    "# specify save location\n",
    "filename = DATA_DIR / f'ClimateGraph_{year}.json'\n",
    "data = json_graph.node_link_data(ClimateGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df3f9665",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'w') as fp:\n",
    "    json.dump(data, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
