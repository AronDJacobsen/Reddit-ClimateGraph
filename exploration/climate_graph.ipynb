{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf2066e7",
   "metadata": {},
   "source": [
    "# Creating the Reddit Network of Climate Discussion Contributors \n",
    "\n",
    "Using the pre-trained Climate Change Sentiment classifier on submissions and comments from Redittors, we model a network of Redittors being pro, neutral or anti to Climate Change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dceab9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import time, datetime\n",
    "\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from nltk import word_tokenize, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f59c6c",
   "metadata": {},
   "source": [
    "## 1) Load Reddit data\n",
    "\n",
    "Initially, the data extracted from Reddit is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8986b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATA_DIR = Path(os.getcwd()).parent / 'data'\n",
    "#DATA_DIR = Path('/work3/s194253')\n",
    "\n",
    "# year\n",
    "year = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb3af1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 40.629838705062866 seconds to load dataframe...\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# load data\n",
    "comments = pd.read_json(DATA_DIR / f'{year}/comments90k_opinion_{year}.json.bz2')\n",
    "submissions = pd.read_json(DATA_DIR / f'{year}/submissions_opinion_{year}.json.bz2')\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Took {end-start} seconds to load dataframe...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5641383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109702, 17)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a50e49cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225763, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606cdf81",
   "metadata": {},
   "source": [
    "## 2) Link comment authors to submission authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "497e0a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionaries\n",
    "comment_authors = dict(zip(comments.id, comments.author))\n",
    "parent = dict(zip(comments.id, comments.parent_id))\n",
    "submission_authors = dict(zip(submissions.id, submissions.author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "726f60c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parent_author(comment_id, comment_authors=comment_authors, parent=parent, submission_authors=submission_authors):\n",
    "    '''Links the comment id to the author of its parent.\n",
    "    \n",
    "    input: comment_id\n",
    "    returns: author'''\n",
    "    \n",
    "    parent_id = parent[comment_id]\n",
    "    \n",
    "    try: # try to look for the parent_id key\n",
    "        if parent_id[:3] == 't1_':\n",
    "            return comment_authors[parent_id[3:]]\n",
    "        if parent_id[:3] == 't3_':\n",
    "            return submission_authors[parent_id[3:]]    \n",
    "    except KeyError: # if parent_id was not extracted in comments or submissions\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe111ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments['parent_author'] = comments['id'].apply(lambda x: parent_author(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b3d6706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of IDs that could not be extracted: 2357/225763 = 0.0104\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of IDs that could not be extracted: {comments['parent_author'].isnull().sum()}/{comments['parent_author'].__len__()} = {comments['parent_author'].isnull().sum() / comments['parent_author'].__len__() :.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caf1b921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223406, 17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove NaN parent authors\n",
    "comments = comments[-comments.parent_author.isnull()].reset_index(drop=True)\n",
    "\n",
    "# size of data\n",
    "comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe37f0dd",
   "metadata": {},
   "source": [
    "## 3) Filter the Reddit comments and submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "979e002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join title and selftext to text attribute in submissions\n",
    "submissions['text'] = submissions.title + \" \" + submissions.selftext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17c1b138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN values for awarders by setting it to 0 or empty list\n",
    "submissions['all_awardings'] = submissions['all_awardings'].fillna(\"\").apply(list)\n",
    "submissions['awarders'] = submissions['awarders'].fillna(\"\").apply(list)\n",
    "submissions['total_awards_received'] = submissions['total_awards_received'].fillna(0)\n",
    "\n",
    "comments['all_awardings'] = comments['all_awardings'].fillna(\"\").apply(list)\n",
    "comments['total_awards_received'] = comments['total_awards_received'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02dfe98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of deleted users: 20163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(203243, 17)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter comments and remove rows with deleted users\n",
    "filtered_comments = comments\n",
    "\n",
    "deleted_users_idx = np.logical_or(filtered_comments.author == '[deleted]', filtered_comments.parent_author == '[deleted]')\n",
    "filtered_comments = filtered_comments[-deleted_users_idx]\n",
    "print(f\"Number of deleted users: {deleted_users_idx.sum()}\")\n",
    "\n",
    "# update index\n",
    "filtered_comments.reset_index(drop=True, inplace=True)\n",
    "filtered_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4585709f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of deleted users: 657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(109045, 17)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter submissions and remove rows with deleted users\n",
    "filtered_submissions = submissions\n",
    "\n",
    "deleted_users_idx = filtered_submissions.author == '[deleted]'\n",
    "filtered_submissions = filtered_submissions[-deleted_users_idx]\n",
    "print(f\"Number of deleted users: {deleted_users_idx.sum()}\")\n",
    "\n",
    "# update index\n",
    "filtered_submissions.reset_index(drop=True, inplace=True)\n",
    "filtered_submissions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffa0af05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-80f9f497bc8c>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_submissions['opinion_score'] = filtered_submissions.opinion.apply(lambda x: op_dict[x])\n",
      "<ipython-input-15-80f9f497bc8c>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_comments['opinion_score'] = filtered_comments.opinion.apply(lambda x: op_dict[x])\n"
     ]
    }
   ],
   "source": [
    "op_dict = {'News': 0,\n",
    "          'Neutral': 0,\n",
    "          'Pro': 1,\n",
    "          'Anti': -1}\n",
    "\n",
    "filtered_submissions['opinion_score'] = filtered_submissions.opinion.apply(lambda x: op_dict[x])\n",
    "filtered_comments['opinion_score'] = filtered_comments.opinion.apply(lambda x: op_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d00e98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>awarders</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>year</th>\n",
       "      <th>opinion</th>\n",
       "      <th>opinion_probs</th>\n",
       "      <th>opinion_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ko3ttz</td>\n",
       "      <td>austria9000</td>\n",
       "      <td>Am I strange or is this fear of 2021 just not ...</td>\n",
       "      <td>I know there is a pandemic and other shit like...</td>\n",
       "      <td>1</td>\n",
       "      <td>collapse</td>\n",
       "      <td>26</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Am I strange or is this fear of 2021 just not ...</td>\n",
       "      <td>{'strang': 1, 'fear': 1, 'logic': 1, 'know': 1...</td>\n",
       "      <td>strang fear logic know pandem shit like climat...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[0.2206094134, 0.5277520404, 0.0356988014, 0.2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ko3gwm</td>\n",
       "      <td>honolulu_oahu_mod</td>\n",
       "      <td>Progress On Climate Change Is Pathway For Econ...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>HawaiiPlantMedicine</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Progress On Climate Change Is Pathway For Econ...</td>\n",
       "      <td>{'progress': 1, 'climat': 1, 'chang': 1, 'path...</td>\n",
       "      <td>progress climat chang pathway econom recoveri ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Pro</td>\n",
       "      <td>[0.1505784031, 0.2912976865, 0.238229698700000...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ko3gk2</td>\n",
       "      <td>honolulu_oahu_mod</td>\n",
       "      <td>Progress On Climate Change Is Pathway For Econ...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>Honolulu</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Progress On Climate Change Is Pathway For Econ...</td>\n",
       "      <td>{'progress': 1, 'climat': 1, 'chang': 1, 'path...</td>\n",
       "      <td>progress climat chang pathway econom recoveri ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Pro</td>\n",
       "      <td>[0.1505784031, 0.2912976865, 0.238229698700000...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ko3fww</td>\n",
       "      <td>TeaDelta</td>\n",
       "      <td>I (21F) have bladder problems and I think it's...</td>\n",
       "      <td>Before I start I wanna say that after I saw a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>raisedbynarcissists</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>I (21F) have bladder problems and I think it's...</td>\n",
       "      <td>{'bladder': 4, 'problem': 5, 'think': 3, 'due'...</td>\n",
       "      <td>bladder problem think due mother start wan na ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[0.2643444703, 0.5466458693, 0.0554297532, 0.1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ko38lj</td>\n",
       "      <td>lavenderah</td>\n",
       "      <td>Could someone suggest me a book which may be a...</td>\n",
       "      <td>\\nsample 1:\\n\\nSan Lorenzo, center of the anci...</td>\n",
       "      <td>1</td>\n",
       "      <td>suggestmeabook</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Could someone suggest me a book which may be a...</td>\n",
       "      <td>{'could': 2, 'someon': 1, 'suggest': 3, 'book'...</td>\n",
       "      <td>could someon suggest book may bit amalgam anth...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[0.2643444703, 0.5466458693, 0.0554297532, 0.1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             author  \\\n",
       "0  ko3ttz        austria9000   \n",
       "1  ko3gwm  honolulu_oahu_mod   \n",
       "2  ko3gk2  honolulu_oahu_mod   \n",
       "3  ko3fww           TeaDelta   \n",
       "4  ko38lj         lavenderah   \n",
       "\n",
       "                                               title  \\\n",
       "0  Am I strange or is this fear of 2021 just not ...   \n",
       "1  Progress On Climate Change Is Pathway For Econ...   \n",
       "2  Progress On Climate Change Is Pathway For Econ...   \n",
       "3  I (21F) have bladder problems and I think it's...   \n",
       "4  Could someone suggest me a book which may be a...   \n",
       "\n",
       "                                            selftext  score  \\\n",
       "0  I know there is a pandemic and other shit like...      1   \n",
       "1                                                         1   \n",
       "2                                                         1   \n",
       "3  Before I start I wanna say that after I saw a ...      1   \n",
       "4  \\nsample 1:\\n\\nSan Lorenzo, center of the anci...      1   \n",
       "\n",
       "             subreddit  num_comments all_awardings awarders  \\\n",
       "0             collapse            26            []       []   \n",
       "1  HawaiiPlantMedicine             1            []       []   \n",
       "2             Honolulu             0            []       []   \n",
       "3  raisedbynarcissists             2            []       []   \n",
       "4       suggestmeabook             1            []       []   \n",
       "\n",
       "   total_awards_received       date  \\\n",
       "0                      0 2021-01-01   \n",
       "1                      0 2021-01-01   \n",
       "2                      0 2021-01-01   \n",
       "3                      0 2021-01-01   \n",
       "4                      0 2021-01-01   \n",
       "\n",
       "                                                text  \\\n",
       "0  Am I strange or is this fear of 2021 just not ...   \n",
       "1  Progress On Climate Change Is Pathway For Econ...   \n",
       "2  Progress On Climate Change Is Pathway For Econ...   \n",
       "3  I (21F) have bladder problems and I think it's...   \n",
       "4  Could someone suggest me a book which may be a...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  {'strang': 1, 'fear': 1, 'logic': 1, 'know': 1...   \n",
       "1  {'progress': 1, 'climat': 1, 'chang': 1, 'path...   \n",
       "2  {'progress': 1, 'climat': 1, 'chang': 1, 'path...   \n",
       "3  {'bladder': 4, 'problem': 5, 'think': 3, 'due'...   \n",
       "4  {'could': 2, 'someon': 1, 'suggest': 3, 'book'...   \n",
       "\n",
       "                                      processed_text  year  opinion  \\\n",
       "0  strang fear logic know pandem shit like climat...  2021  Neutral   \n",
       "1  progress climat chang pathway econom recoveri ...  2021      Pro   \n",
       "2  progress climat chang pathway econom recoveri ...  2021      Pro   \n",
       "3  bladder problem think due mother start wan na ...  2021  Neutral   \n",
       "4  could someon suggest book may bit amalgam anth...  2021  Neutral   \n",
       "\n",
       "                                       opinion_probs  opinion_score  \n",
       "0  [0.2206094134, 0.5277520404, 0.0356988014, 0.2...              0  \n",
       "1  [0.1505784031, 0.2912976865, 0.238229698700000...              1  \n",
       "2  [0.1505784031, 0.2912976865, 0.238229698700000...              1  \n",
       "3  [0.2643444703, 0.5466458693, 0.0554297532, 0.1...              0  \n",
       "4  [0.2643444703, 0.5466458693, 0.0554297532, 0.1...              0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_submissions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5e6e12",
   "metadata": {},
   "source": [
    "## 4) Handle author metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74bc6f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(df, reddit_type='comment'):\n",
    "    \n",
    "    author_df = pd.DataFrame()\n",
    "    \n",
    "    groups = df.groupby(by='author')\n",
    "\n",
    "    author_df['text'] = groups.text.apply(lambda x: list(x))\n",
    "    author_df['all_awardings'] = groups.all_awardings.apply(lambda x: np.concatenate([*x]))\n",
    "    author_df['total_awards_received'] = groups.total_awards_received.sum()\n",
    "    author_df['total_awards_received'] = groups.total_awards_received.sum()\n",
    "    author_df['score'] = groups.score.sum()\n",
    "    author_df[f'first_{reddit_type}'] = groups.date.apply(lambda x: x.sort_values(ascending=True).iloc[0].timestamp())\n",
    "    author_df[f'last_{reddit_type}'] = groups.date.apply(lambda x: x.sort_values(ascending=True).iloc[-1].timestamp())\n",
    "    author_df[f'num_{reddit_type}s'] = groups.apply(lambda x: x.__len__())\n",
    "    author_df['opinion_score'] = groups.opinion_score.mean()\n",
    "    \n",
    "    if reddit_type == 'comment':\n",
    "        author_df['controversiality'] = groups.controversiality.sum()\n",
    "    \n",
    "    return author_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f68fe633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting metadata for comments...\n",
      "\n",
      "Extracting metadata for submissions...\n"
     ]
    }
   ],
   "source": [
    "#extract metadata\n",
    "print(\"Extracting metadata for comments...\")\n",
    "author_comment = get_metadata(filtered_comments, reddit_type='comment')\n",
    "\n",
    "print(\"\\nExtracting metadata for submissions...\")\n",
    "author_submission = get_metadata(filtered_submissions, reddit_type='submission')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3842948",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_joined = author_comment.join(author_submission, on='author', lsuffix='_c', rsuffix='_s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db6a3838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "Successfully combined dataframe!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>score</th>\n",
       "      <th>opinion_score</th>\n",
       "      <th>first_comment</th>\n",
       "      <th>last_comment</th>\n",
       "      <th>first_submission</th>\n",
       "      <th>last_submission</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>num_submissions</th>\n",
       "      <th>comment_controversiality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TheGudu</th>\n",
       "      <td>Sooooooooooooo funny!!!! Well stop spreading s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>1.635466e+09</td>\n",
       "      <td>1.637885e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ask_Who_Owes_Me_Gold</th>\n",
       "      <td>Consumer preferences are a big factor too. The...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.628122e+09</td>\n",
       "      <td>1.628122e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>animalsanddepression</th>\n",
       "      <td>seconding this. I have an insane needle phobia...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.628986e+09</td>\n",
       "      <td>1.628986e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ArtfulArtificer</th>\n",
       "      <td>You ever play the start of FF7 and see what ou...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.628467e+09</td>\n",
       "      <td>1.628467e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>THICCTHIGHSNOLIES</th>\n",
       "      <td>The elites will, they already have their survi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.620778e+09</td>\n",
       "      <td>1.620778e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roboticsammy</th>\n",
       "      <td>Like it's so easy to \"just move to where your ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.639872e+09</td>\n",
       "      <td>1.639872e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ThinkImpermanence</th>\n",
       "      <td>The science behind that film has been debunked...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.633392e+09</td>\n",
       "      <td>1.633392e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Limbolocal</th>\n",
       "      <td>Or aliens</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.630886e+09</td>\n",
       "      <td>1.630886e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InFearn0</th>\n",
       "      <td>\"Soylent Gas is people!\" Gaia worlds aren't mo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.621382e+09</td>\n",
       "      <td>1.621382e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bennzo1238</th>\n",
       "      <td>Yeah, sure - but surely a v small percentage? ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.631923e+09</td>\n",
       "      <td>1.631923e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   text  \\\n",
       "author                                                                    \n",
       "TheGudu               Sooooooooooooo funny!!!! Well stop spreading s...   \n",
       "Ask_Who_Owes_Me_Gold  Consumer preferences are a big factor too. The...   \n",
       "animalsanddepression  seconding this. I have an insane needle phobia...   \n",
       "ArtfulArtificer       You ever play the start of FF7 and see what ou...   \n",
       "THICCTHIGHSNOLIES     The elites will, they already have their survi...   \n",
       "Roboticsammy          Like it's so easy to \"just move to where your ...   \n",
       "ThinkImpermanence     The science behind that film has been debunked...   \n",
       "Limbolocal                                                    Or aliens   \n",
       "InFearn0              \"Soylent Gas is people!\" Gaia worlds aren't mo...   \n",
       "bennzo1238            Yeah, sure - but surely a v small percentage? ...   \n",
       "\n",
       "                     all_awardings  total_awards_received  score  \\\n",
       "author                                                             \n",
       "TheGudu                         []                    0.0  -13.0   \n",
       "Ask_Who_Owes_Me_Gold            []                    0.0    2.0   \n",
       "animalsanddepression            []                    0.0    1.0   \n",
       "ArtfulArtificer                 []                    0.0    1.0   \n",
       "THICCTHIGHSNOLIES               []                    0.0    2.0   \n",
       "Roboticsammy                    []                    0.0    3.0   \n",
       "ThinkImpermanence               []                    0.0    3.0   \n",
       "Limbolocal                      []                    0.0    1.0   \n",
       "InFearn0                        []                    0.0   18.0   \n",
       "bennzo1238                      []                    0.0   93.0   \n",
       "\n",
       "                      opinion_score  first_comment  last_comment  \\\n",
       "author                                                             \n",
       "TheGudu                   -0.250000   1.635466e+09  1.637885e+09   \n",
       "Ask_Who_Owes_Me_Gold       0.000000   1.628122e+09  1.628122e+09   \n",
       "animalsanddepression       0.000000   1.628986e+09  1.628986e+09   \n",
       "ArtfulArtificer            0.000000   1.628467e+09  1.628467e+09   \n",
       "THICCTHIGHSNOLIES          0.000000   1.620778e+09  1.620778e+09   \n",
       "Roboticsammy               0.166667   1.639872e+09  1.639872e+09   \n",
       "ThinkImpermanence         -0.500000   1.633392e+09  1.633392e+09   \n",
       "Limbolocal                 0.000000   1.630886e+09  1.630886e+09   \n",
       "InFearn0                   0.000000   1.621382e+09  1.621382e+09   \n",
       "bennzo1238                 0.000000   1.631923e+09  1.631923e+09   \n",
       "\n",
       "                      first_submission  last_submission  num_comments  \\\n",
       "author                                                                  \n",
       "TheGudu                            NaN              NaN             4   \n",
       "Ask_Who_Owes_Me_Gold               NaN              NaN             1   \n",
       "animalsanddepression               NaN              NaN             1   \n",
       "ArtfulArtificer                    NaN              NaN             1   \n",
       "THICCTHIGHSNOLIES                  NaN              NaN             1   \n",
       "Roboticsammy                       NaN              NaN             3   \n",
       "ThinkImpermanence                  NaN              NaN             1   \n",
       "Limbolocal                         NaN              NaN             1   \n",
       "InFearn0                           NaN              NaN             2   \n",
       "bennzo1238                         NaN              NaN             3   \n",
       "\n",
       "                      num_submissions  comment_controversiality  \n",
       "author                                                           \n",
       "TheGudu                           NaN                       0.0  \n",
       "Ask_Who_Owes_Me_Gold              NaN                       0.0  \n",
       "animalsanddepression              NaN                       0.0  \n",
       "ArtfulArtificer                   NaN                       0.0  \n",
       "THICCTHIGHSNOLIES                 NaN                       0.0  \n",
       "Roboticsammy                      NaN                       0.0  \n",
       "ThinkImpermanence                 NaN                       0.0  \n",
       "Limbolocal                        NaN                       0.0  \n",
       "InFearn0                          NaN                       0.0  \n",
       "bennzo1238                        NaN                       0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author = pd.DataFrame()\n",
    "print(\"Running...\")\n",
    "for attr, fill in {'text': 'list', 'all_awardings': 'list', 'total_awards_received': 'num', 'score': 'num', 'opinion_score':'num'}.items():\n",
    "    for letter in ['s', 'c']:\n",
    "        \n",
    "        # reformat rows\n",
    "        if fill == 'list':\n",
    "            author_joined[f'{attr}_{letter}'] = author_joined[f'{attr}_{letter}'].fillna(\"\").apply(list)\n",
    "        elif fill == 'num':\n",
    "            author_joined[f'{attr}_{letter}'] = author_joined[f'{attr}_{letter}'].fillna(0)\n",
    "            \n",
    "    # create combined dataframe\n",
    "    author[f'{attr}'] = author_joined[f'{attr}_s'] + author_joined[f'{attr}_c']\n",
    "    if attr == 'opinion_score':\n",
    "        author[f'{attr}'] /= 2\n",
    "    \n",
    "print(\"Successfully combined dataframe!\")\n",
    "\n",
    "# keep relevant attributes\n",
    "aoi = ['first_comment', 'last_comment', \n",
    "       'first_submission', 'last_submission', \n",
    "       'num_comments', 'num_submissions',  \n",
    "       'controversiality']\n",
    "author[aoi] = author_joined[aoi]\n",
    "\n",
    "# modify list of texts to one large string\n",
    "author['text'] = author['text'].apply(lambda x: ' '.join(str(v) for v in x))\n",
    "\n",
    "# rename\n",
    "author = author.rename(columns={'controversiality':'comment_controversiality'})\n",
    "author.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21deb5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stop-words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# add webpages to stopwords\n",
    "stop_words.add('http') \n",
    "stop_words.add('https')\n",
    "\n",
    "# Preprocess the text \n",
    "porter = PorterStemmer()\n",
    "exclusions = {'RT'}\n",
    "\n",
    "# define tokenizing function\n",
    "clean = lambda x: Counter([porter.stem(word_token).lower() for word_token in word_tokenize(x) \\\n",
    "                       if word_token.lower() not in stop_words \\\n",
    "                       and word_token.isalpha() \\\n",
    "                       and word_token not in exclusions])\n",
    "\n",
    "# apply tokenizing to texts - apply for seeing progress bar WHEN running\n",
    "tokens = author['text'].apply(lambda text: clean(text))\n",
    "author['tokens'] = tokens\n",
    "\n",
    "# join tokens to one string\n",
    "author['processed_text'] = author['tokens'].apply(lambda x: ' '.join(str(v) for v in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c6c0ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "author.to_json(DATA_DIR / f'author_opinion_{year}.json.bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac22d7c",
   "metadata": {},
   "source": [
    "## 5) Create ClimateGraph from edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c7d64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "author = pd.read_json(DATA_DIR / f'author_opinion_{year}.json.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8969247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>score</th>\n",
       "      <th>opinion_score</th>\n",
       "      <th>first_comment</th>\n",
       "      <th>last_comment</th>\n",
       "      <th>first_submission</th>\n",
       "      <th>last_submission</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>num_submissions</th>\n",
       "      <th>comment_controversiality</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MeMuzzta</th>\n",
       "      <td>They're a bunch of morons and anyone condoning...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1636156800</td>\n",
       "      <td>1636243200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'bunch': 2, 'moron': 3, 'anyon': 1, 'condon':...</td>\n",
       "      <td>bunch moron anyon condon behaviour also see en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sp0il</th>\n",
       "      <td>Yall really get your panties in a bunch about ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1625270400</td>\n",
       "      <td>1625270400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'yall': 1, 'realli': 1, 'get': 1, 'panti': 1,...</td>\n",
       "      <td>yall realli get panti bunch everi slightli mem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DanCastellaneta</th>\n",
       "      <td>With context to the US, the Middle East and Au...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1626307200</td>\n",
       "      <td>1626307200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'context': 1, 'us': 2, 'middl': 2, 'east': 2,...</td>\n",
       "      <td>context us middl east australia part boil ment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spoobydoo</th>\n",
       "      <td>If people want to make a collective effort to ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1639872000</td>\n",
       "      <td>1639872000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'peopl': 1, 'want': 1, 'make': 1, 'collect': ...</td>\n",
       "      <td>peopl want make collect effort battl climat ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comfortable-Event239</th>\n",
       "      <td>Karen \\nit’s to get it in the news, and it wor...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1631923200</td>\n",
       "      <td>1631923200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'karen': 1, 'get': 1, 'news': 1, 'work': 1, '...</td>\n",
       "      <td>karen get news work emerg die address littl ho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   text  \\\n",
       "MeMuzzta              They're a bunch of morons and anyone condoning...   \n",
       "Sp0il                 Yall really get your panties in a bunch about ...   \n",
       "DanCastellaneta       With context to the US, the Middle East and Au...   \n",
       "spoobydoo             If people want to make a collective effort to ...   \n",
       "Comfortable-Event239  Karen \\nit’s to get it in the news, and it wor...   \n",
       "\n",
       "                     all_awardings  total_awards_received  score  \\\n",
       "MeMuzzta                        []                      0      2   \n",
       "Sp0il                           []                      0     13   \n",
       "DanCastellaneta                 []                      0      6   \n",
       "spoobydoo                       []                      0      1   \n",
       "Comfortable-Event239            []                      0      2   \n",
       "\n",
       "                      opinion_score  first_comment  last_comment  \\\n",
       "MeMuzzta                        0.0     1636156800    1636243200   \n",
       "Sp0il                           0.0     1625270400    1625270400   \n",
       "DanCastellaneta                -0.5     1626307200    1626307200   \n",
       "spoobydoo                       0.0     1639872000    1639872000   \n",
       "Comfortable-Event239            0.0     1631923200    1631923200   \n",
       "\n",
       "                      first_submission  last_submission  num_comments  \\\n",
       "MeMuzzta                           NaN              NaN             2   \n",
       "Sp0il                              NaN              NaN             1   \n",
       "DanCastellaneta                    NaN              NaN             1   \n",
       "spoobydoo                          NaN              NaN             1   \n",
       "Comfortable-Event239               NaN              NaN             1   \n",
       "\n",
       "                      num_submissions  comment_controversiality  \\\n",
       "MeMuzzta                          NaN                         0   \n",
       "Sp0il                             NaN                         0   \n",
       "DanCastellaneta                   NaN                         0   \n",
       "spoobydoo                         NaN                         0   \n",
       "Comfortable-Event239              NaN                         0   \n",
       "\n",
       "                                                                 tokens  \\\n",
       "MeMuzzta              {'bunch': 2, 'moron': 3, 'anyon': 1, 'condon':...   \n",
       "Sp0il                 {'yall': 1, 'realli': 1, 'get': 1, 'panti': 1,...   \n",
       "DanCastellaneta       {'context': 1, 'us': 2, 'middl': 2, 'east': 2,...   \n",
       "spoobydoo             {'peopl': 1, 'want': 1, 'make': 1, 'collect': ...   \n",
       "Comfortable-Event239  {'karen': 1, 'get': 1, 'news': 1, 'work': 1, '...   \n",
       "\n",
       "                                                         processed_text  \n",
       "MeMuzzta              bunch moron anyon condon behaviour also see en...  \n",
       "Sp0il                 yall realli get panti bunch everi slightli mem...  \n",
       "DanCastellaneta       context us middl east australia part boil ment...  \n",
       "spoobydoo             peopl want make collect effort battl climat ch...  \n",
       "Comfortable-Event239  karen get news work emerg die address littl ho...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea94826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the weighted edgelist by counting - using score as a randomly picked attributed to obtain a single pd.Series\n",
    "weighted_edgelist = filtered_comments.groupby(by=['author', 'parent_author']).count().score\n",
    "weighted_edgelist = weighted_edgelist.reset_index().rename(columns={'score':'weight'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae243899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>parent_author</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87331</th>\n",
       "      <td>TiredForEternity</td>\n",
       "      <td>lost_castle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22987</th>\n",
       "      <td>DeadlyLemming</td>\n",
       "      <td>throwaway12131214121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49807</th>\n",
       "      <td>LichPineapple</td>\n",
       "      <td>newnemo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62488</th>\n",
       "      <td>Ok_Carrot_5475</td>\n",
       "      <td>Im_Sapphire</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41926</th>\n",
       "      <td>Infernalism</td>\n",
       "      <td>Godhealer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author         parent_author  weight\n",
       "87331  TiredForEternity           lost_castle       1\n",
       "22987     DeadlyLemming  throwaway12131214121       1\n",
       "49807     LichPineapple               newnemo       1\n",
       "62488    Ok_Carrot_5475           Im_Sapphire       1\n",
       "41926       Infernalism             Godhealer       1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_edgelist.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58024aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat weighted edgelist to 3-tuples\n",
    "edgelist = list(zip(weighted_edgelist.author, weighted_edgelist.parent_author, weighted_edgelist.weight))\n",
    "\n",
    "# construct graph\n",
    "ClimateGraph = nx.DiGraph()\n",
    "ClimateGraph.add_weighted_edges_from(edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40a56cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weight of edge of first link\n",
    "ClimateGraph.get_edge_data('redwolf177', 'TheNoHeart')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931deb60",
   "metadata": {},
   "source": [
    "## 6) Add node attributes to ClimateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05df161b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe617f705dc4eb7afd3e6bf7dc6d74a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/95507 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for redditor in tqdm(author.index):\n",
    "    meta = {redditor: author.loc[redditor].to_dict()}\n",
    "    nx.set_node_attributes(ClimateGraph, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0c3a8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean graph\n",
    "ClimateGraph.remove_edges_from(nx.selfloop_edges(ClimateGraph))\n",
    "\n",
    "# remove nodes that do not have metadata\n",
    "remove_nodes = []\n",
    "for k, v in ClimateGraph.nodes(data=True):\n",
    "    try: \n",
    "        check = v['opinion_score']\n",
    "    except KeyError:\n",
    "        remove_nodes.append(k)\n",
    "\n",
    "ClimateGraph.remove_nodes_from(remove_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72736157",
   "metadata": {},
   "source": [
    "## 5) Save ClimateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f697291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save graph as json\n",
    "from networkx.readwrite import json_graph\n",
    "import json\n",
    "\n",
    "# specify save location\n",
    "filename = DATA_DIR / f'ClimateGraph_{year}.json'\n",
    "data = json_graph.node_link_data(ClimateGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df3f9665",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'w') as fp:\n",
    "    json.dump(data, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
