{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f7721775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.1'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2066e7",
   "metadata": {},
   "source": [
    "# Creating the Reddit Network of Climate Discussion Contributors \n",
    "\n",
    "Using the pre-trained Climate Change Sentiment classifier on submissions and comments from Redittors, we model a network of Redittors being pro, neutral or anti to Climate Change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dceab9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import time, datetime\n",
    "\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from nltk import word_tokenize, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f59c6c",
   "metadata": {},
   "source": [
    "## 1) Load Reddit data\n",
    "\n",
    "Initially, the data extracted from Reddit is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8986b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATA_DIR = Path(os.getcwd()).parent / 'data'\n",
    "#DATA_DIR = Path('/work3/s194253')\n",
    "\n",
    "# year\n",
    "year = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb3af1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 45.28191637992859 seconds to load dataframe...\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# load data\n",
    "comments = pd.read_json(DATA_DIR / f'{year}/comments90k_opinion_{year}.json.bz2')\n",
    "submissions = pd.read_json(DATA_DIR / f'{year}/submissions_opinion_{year}.json.bz2')\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Took {end-start} seconds to load dataframe...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5641383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82046, 17)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a50e49cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151622, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606cdf81",
   "metadata": {},
   "source": [
    "## 2) Link comment authors to submission authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "497e0a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionaries\n",
    "comment_authors = dict(zip(comments.id, comments.author))\n",
    "parent = dict(zip(comments.id, comments.parent_id))\n",
    "submission_authors = dict(zip(submissions.id, submissions.author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "726f60c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parent_author(comment_id, comment_authors=comment_authors, parent=parent, submission_authors=submission_authors):\n",
    "    '''Links the comment id to the author of its parent.\n",
    "    \n",
    "    input: comment_id\n",
    "    returns: author'''\n",
    "    \n",
    "    parent_id = parent[comment_id]\n",
    "    \n",
    "    try: # try to look for the parent_id key\n",
    "        if parent_id[:3] == 't1_':\n",
    "            return comment_authors[parent_id[3:]]\n",
    "        if parent_id[:3] == 't3_':\n",
    "            return submission_authors[parent_id[3:]]    \n",
    "    except KeyError: # if parent_id was not extracted in comments or submissions\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe111ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b421b8560a374149866fc9fd9dcc329e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/151622 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comments['parent_author'] = comments['id'].progress_apply(lambda x: parent_author(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b3d6706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of IDs that could not be extracted: 960/151622 = 0.0063\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of IDs that could not be extracted: {comments['parent_author'].isnull().sum()}/{comments['parent_author'].__len__()} = {comments['parent_author'].isnull().sum() / comments['parent_author'].__len__() :.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caf1b921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150662, 17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove NaN parent authors\n",
    "comments = comments[-comments.parent_author.isnull()].reset_index(drop=True)\n",
    "\n",
    "# size of data\n",
    "comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe37f0dd",
   "metadata": {},
   "source": [
    "## 3) Filter the Reddit comments and submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "979e002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join title and selftext to text attribute in submissions\n",
    "submissions['text'] = submissions.title + \" \" + submissions.selftext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17c1b138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN values for awarders by setting it to 0 or empty list\n",
    "submissions['all_awardings'] = submissions['all_awardings'].fillna(\"\").apply(list)\n",
    "submissions['awarders'] = submissions['awarders'].fillna(\"\").apply(list)\n",
    "submissions['total_awards_received'] = submissions['total_awards_received'].fillna(0)\n",
    "\n",
    "comments['all_awardings'] = comments['all_awardings'].fillna(\"\").apply(list)\n",
    "comments['total_awards_received'] = comments['total_awards_received'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02dfe98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of deleted users: 9173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(141489, 17)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter comments and remove rows with deleted users\n",
    "filtered_comments = comments\n",
    "\n",
    "deleted_users_idx = np.logical_or(filtered_comments.author == '[deleted]', filtered_comments.parent_author == '[deleted]')\n",
    "filtered_comments = filtered_comments[-deleted_users_idx]\n",
    "print(f\"Number of deleted users: {deleted_users_idx.sum()}\")\n",
    "\n",
    "# update index\n",
    "filtered_comments.reset_index(drop=True, inplace=True)\n",
    "filtered_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4585709f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of deleted users: 659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(81387, 17)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter submissions and remove rows with deleted users\n",
    "filtered_submissions = submissions\n",
    "\n",
    "deleted_users_idx = filtered_submissions.author == '[deleted]'\n",
    "filtered_submissions = filtered_submissions[-deleted_users_idx]\n",
    "print(f\"Number of deleted users: {deleted_users_idx.sum()}\")\n",
    "\n",
    "# update index\n",
    "filtered_submissions.reset_index(drop=True, inplace=True)\n",
    "filtered_submissions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffa0af05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c7/h3k1399d5gvgm2_wy7wjs_yc0000gn/T/ipykernel_10614/3806665257.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_submissions['opinion_score'] = filtered_submissions.opinion.apply(lambda x: op_dict[x])\n",
      "/var/folders/c7/h3k1399d5gvgm2_wy7wjs_yc0000gn/T/ipykernel_10614/3806665257.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_comments['opinion_score'] = filtered_comments.opinion.apply(lambda x: op_dict[x])\n"
     ]
    }
   ],
   "source": [
    "op_dict = {'News': 0,\n",
    "          'Neutral': 0,\n",
    "          'Pro': 1,\n",
    "          'Anti': -1}\n",
    "\n",
    "filtered_submissions['opinion_score'] = filtered_submissions.opinion.apply(lambda x: op_dict[x])\n",
    "filtered_comments['opinion_score'] = filtered_comments.opinion.apply(lambda x: op_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d00e98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>awarders</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>year</th>\n",
       "      <th>opinion</th>\n",
       "      <th>opinion_probs</th>\n",
       "      <th>opinion_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eicndu</td>\n",
       "      <td>toronto_news</td>\n",
       "      <td>Could algae be a secret weapon in the climate ...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>u_toronto_news</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Could algae be a secret weapon in the climate ...</td>\n",
       "      <td>{'could': 1, 'alga': 1, 'secret': 1, 'weapon':...</td>\n",
       "      <td>could alga secret weapon climat chang crisi ma...</td>\n",
       "      <td>2020</td>\n",
       "      <td>News</td>\n",
       "      <td>[0.2649832925, 0.1244659196, 0.4741758891, 0.1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eicmqm</td>\n",
       "      <td>bogbodybutch</td>\n",
       "      <td>Know their Names: Eight Activists Assassinated...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>ClimateOffensive</td>\n",
       "      <td>15</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Know their Names: Eight Activists Assassinated...</td>\n",
       "      <td>{'know': 1, 'name': 1, 'eight': 1, 'activist':...</td>\n",
       "      <td>know name eight activist assassin fight climat...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Pro</td>\n",
       "      <td>[0.145520545, 0.13338547550000002, 0.320116649...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eicm79</td>\n",
       "      <td>jackson-on-reddit</td>\n",
       "      <td>The Australian Prime Minister still refuses to...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>ABoringDystopia</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>The Australian Prime Minister still refuses to...</td>\n",
       "      <td>{'australian': 1, 'prime': 1, 'minist': 1, 'st...</td>\n",
       "      <td>australian prime minist still refus take actio...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Pro</td>\n",
       "      <td>[0.12853447040000002, 0.08645230100000001, 0.1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eichqb</td>\n",
       "      <td>babyyourearichman111</td>\n",
       "      <td>/u/nowyourmad on CMV: Disregarding Economists'...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>1</td>\n",
       "      <td>TalkativePeople</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>/u/nowyourmad on CMV: Disregarding Economists'...</td>\n",
       "      <td>{'cmv': 1, 'disregard': 2, 'economist': 1, 'co...</td>\n",
       "      <td>cmv disregard economist consensu thing like fr...</td>\n",
       "      <td>2020</td>\n",
       "      <td>Anti</td>\n",
       "      <td>[0.3567703754, 0.2436021857, 0.1100517669, 0.2...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eicgj2</td>\n",
       "      <td>YeetOnMyKids</td>\n",
       "      <td>Climate change fake</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>okbuddyretard</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>Climate change fake</td>\n",
       "      <td>{'climat': 1, 'chang': 1, 'fake': 1}</td>\n",
       "      <td>climat chang fake</td>\n",
       "      <td>2020</td>\n",
       "      <td>Anti</td>\n",
       "      <td>[0.4198382285, 0.3151598512, 0.0729579884, 0.1...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                author  \\\n",
       "0  eicndu          toronto_news   \n",
       "1  eicmqm          bogbodybutch   \n",
       "2  eicm79     jackson-on-reddit   \n",
       "3  eichqb  babyyourearichman111   \n",
       "4  eicgj2          YeetOnMyKids   \n",
       "\n",
       "                                               title   selftext  score  \\\n",
       "0  Could algae be a secret weapon in the climate ...                 1   \n",
       "1  Know their Names: Eight Activists Assassinated...                 1   \n",
       "2  The Australian Prime Minister still refuses to...                 1   \n",
       "3  /u/nowyourmad on CMV: Disregarding Economists'...  [removed]      1   \n",
       "4                                Climate change fake                 1   \n",
       "\n",
       "          subreddit  num_comments all_awardings awarders  \\\n",
       "0    u_toronto_news             0            []       []   \n",
       "1  ClimateOffensive            15            []       []   \n",
       "2   ABoringDystopia             5            []       []   \n",
       "3   TalkativePeople             0            []       []   \n",
       "4     okbuddyretard             0            []       []   \n",
       "\n",
       "   total_awards_received       date  \\\n",
       "0                      0 2020-01-01   \n",
       "1                      0 2020-01-01   \n",
       "2                      0 2020-01-01   \n",
       "3                      0 2020-01-01   \n",
       "4                      0 2020-01-01   \n",
       "\n",
       "                                                text  \\\n",
       "0  Could algae be a secret weapon in the climate ...   \n",
       "1  Know their Names: Eight Activists Assassinated...   \n",
       "2  The Australian Prime Minister still refuses to...   \n",
       "3  /u/nowyourmad on CMV: Disregarding Economists'...   \n",
       "4                               Climate change fake    \n",
       "\n",
       "                                              tokens  \\\n",
       "0  {'could': 1, 'alga': 1, 'secret': 1, 'weapon':...   \n",
       "1  {'know': 1, 'name': 1, 'eight': 1, 'activist':...   \n",
       "2  {'australian': 1, 'prime': 1, 'minist': 1, 'st...   \n",
       "3  {'cmv': 1, 'disregard': 2, 'economist': 1, 'co...   \n",
       "4               {'climat': 1, 'chang': 1, 'fake': 1}   \n",
       "\n",
       "                                      processed_text  year opinion  \\\n",
       "0  could alga secret weapon climat chang crisi ma...  2020    News   \n",
       "1  know name eight activist assassin fight climat...  2020     Pro   \n",
       "2  australian prime minist still refus take actio...  2020     Pro   \n",
       "3  cmv disregard economist consensu thing like fr...  2020    Anti   \n",
       "4                                  climat chang fake  2020    Anti   \n",
       "\n",
       "                                       opinion_probs  opinion_score  \n",
       "0  [0.2649832925, 0.1244659196, 0.4741758891, 0.1...              0  \n",
       "1  [0.145520545, 0.13338547550000002, 0.320116649...              1  \n",
       "2  [0.12853447040000002, 0.08645230100000001, 0.1...              1  \n",
       "3  [0.3567703754, 0.2436021857, 0.1100517669, 0.2...             -1  \n",
       "4  [0.4198382285, 0.3151598512, 0.0729579884, 0.1...             -1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_submissions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5e6e12",
   "metadata": {},
   "source": [
    "## 4) Handle author metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74bc6f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(df, reddit_type='comment'):\n",
    "    \n",
    "    author_df = pd.DataFrame()\n",
    "    \n",
    "    groups = df.groupby(by='author')\n",
    "\n",
    "    author_df['text'] = groups.text.progress_apply(lambda x: list(x))\n",
    "    author_df['all_awardings'] = groups.all_awardings.progress_apply(lambda x: np.concatenate([*x]))\n",
    "    author_df['total_awards_received'] = groups.total_awards_received.sum()\n",
    "    author_df['total_awards_received'] = groups.total_awards_received.sum()\n",
    "    author_df['score'] = groups.score.sum()\n",
    "    author_df[f'first_{reddit_type}'] = groups.date.progress_apply(lambda x: x.sort_values(ascending=True).iloc[0].timestamp())\n",
    "    author_df[f'last_{reddit_type}'] = groups.date.progress_apply(lambda x: x.sort_values(ascending=True).iloc[-1].timestamp())\n",
    "    author_df[f'num_{reddit_type}s'] = groups.progress_apply(lambda x: x.__len__())\n",
    "    author_df['opinion_score'] = groups.opinion_score.mean()\n",
    "    \n",
    "    if reddit_type == 'comment':\n",
    "        author_df['controversiality'] = groups.controversiality.sum()\n",
    "    \n",
    "    return author_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f68fe633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting metadata for comments...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71861d1b7564bf6ae87331093abf522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb98eb2cf88474d976ef8eccd16f767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9408b653d94c52a800b7372a42e164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a7ab2815a84b1691b3bff5aff48726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aadb0addf3e4e41ad6b08b03caec661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting metadata for submissions...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2984360920f8490d8e90b76439b554f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5d96ead44043a598fc91af88f80c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac053142ed8c4f9482078ec2c48aa709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280733ea83544eb6b07de5b5220050d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8657dc4f2174ab79e8064209651fd64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33624 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#extract metadata\n",
    "print(\"Extracting metadata for comments...\")\n",
    "author_comment = get_metadata(filtered_comments, reddit_type='comment')\n",
    "\n",
    "print(\"\\nExtracting metadata for submissions...\")\n",
    "author_submission = get_metadata(filtered_submissions, reddit_type='submission')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3842948",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_joined = author_comment.join(author_submission, on='author', lsuffix='_c', rsuffix='_s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db6a3838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "Successfully combined dataframe!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aef66d023af48bc805b28a2fbad9cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>score</th>\n",
       "      <th>opinion_score</th>\n",
       "      <th>first_comment</th>\n",
       "      <th>last_comment</th>\n",
       "      <th>first_submission</th>\n",
       "      <th>last_submission</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>num_submissions</th>\n",
       "      <th>comment_controversiality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>brd3001</th>\n",
       "      <td>Check out the protopic / elidel withdrawal gro...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.607818e+09</td>\n",
       "      <td>1.607818e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lotofmurkamiinthehal</th>\n",
       "      <td>Rent free 100% r/MGTOW in the wild</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.583798e+09</td>\n",
       "      <td>1.583798e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sl_1138</th>\n",
       "      <td>We all died inside last night</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.601424e+09</td>\n",
       "      <td>1.601424e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WaywardTraveller</th>\n",
       "      <td>Here's the thing: Many parts of Alberta are re...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.591661e+09</td>\n",
       "      <td>1.591661e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fukwhutuheard</th>\n",
       "      <td>one crises at a time please</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.588896e+09</td>\n",
       "      <td>1.588896e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blubburtron</th>\n",
       "      <td>It's clearly someone recording security cam fo...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.600128e+09</td>\n",
       "      <td>1.600128e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>childish-grambino</th>\n",
       "      <td>Apply this generosity to your employees and th...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.581898e+09</td>\n",
       "      <td>1.581898e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wakarimasen420</th>\n",
       "      <td>And Biden helped put a whole bunch more people...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.605744e+09</td>\n",
       "      <td>1.605830e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bNyeTheVRGuy</th>\n",
       "      <td>Use bots to launch a mass information campaign...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.598573e+09</td>\n",
       "      <td>1.598573e+09</td>\n",
       "      <td>1.598486e+09</td>\n",
       "      <td>1.598486e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spec2re</th>\n",
       "      <td>Agreed, you can't explain the tides, let alone...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1.603325e+09</td>\n",
       "      <td>1.603325e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   text  \\\n",
       "author                                                                    \n",
       "brd3001               Check out the protopic / elidel withdrawal gro...   \n",
       "lotofmurkamiinthehal                 Rent free 100% r/MGTOW in the wild   \n",
       "sl_1138                                   We all died inside last night   \n",
       "WaywardTraveller      Here's the thing: Many parts of Alberta are re...   \n",
       "fukwhutuheard                               one crises at a time please   \n",
       "blubburtron           It's clearly someone recording security cam fo...   \n",
       "childish-grambino     Apply this generosity to your employees and th...   \n",
       "Wakarimasen420        And Biden helped put a whole bunch more people...   \n",
       "bNyeTheVRGuy          Use bots to launch a mass information campaign...   \n",
       "spec2re               Agreed, you can't explain the tides, let alone...   \n",
       "\n",
       "                     all_awardings  total_awards_received  score  \\\n",
       "author                                                             \n",
       "brd3001                         []                    0.0    1.0   \n",
       "lotofmurkamiinthehal            []                    0.0    6.0   \n",
       "sl_1138                         []                    0.0    1.0   \n",
       "WaywardTraveller                []                    0.0    5.0   \n",
       "fukwhutuheard                   []                    0.0    1.0   \n",
       "blubburtron                     []                    0.0    4.0   \n",
       "childish-grambino               []                    0.0    1.0   \n",
       "Wakarimasen420                  []                    0.0   13.0   \n",
       "bNyeTheVRGuy                    []                    0.0    2.0   \n",
       "spec2re                         []                    0.0    4.0   \n",
       "\n",
       "                      opinion_score  first_comment  last_comment  \\\n",
       "author                                                             \n",
       "brd3001                         0.0   1.607818e+09  1.607818e+09   \n",
       "lotofmurkamiinthehal            0.0   1.583798e+09  1.583798e+09   \n",
       "sl_1138                         0.0   1.601424e+09  1.601424e+09   \n",
       "WaywardTraveller                0.0   1.591661e+09  1.591661e+09   \n",
       "fukwhutuheard                   0.0   1.588896e+09  1.588896e+09   \n",
       "blubburtron                     0.0   1.600128e+09  1.600128e+09   \n",
       "childish-grambino               0.0   1.581898e+09  1.581898e+09   \n",
       "Wakarimasen420                  0.0   1.605744e+09  1.605830e+09   \n",
       "bNyeTheVRGuy                    0.0   1.598573e+09  1.598573e+09   \n",
       "spec2re                        -0.5   1.603325e+09  1.603325e+09   \n",
       "\n",
       "                      first_submission  last_submission  num_comments  \\\n",
       "author                                                                  \n",
       "brd3001                            NaN              NaN             1   \n",
       "lotofmurkamiinthehal               NaN              NaN             2   \n",
       "sl_1138                            NaN              NaN             1   \n",
       "WaywardTraveller                   NaN              NaN             1   \n",
       "fukwhutuheard                      NaN              NaN             1   \n",
       "blubburtron                        NaN              NaN             1   \n",
       "childish-grambino                  NaN              NaN             1   \n",
       "Wakarimasen420                     NaN              NaN             4   \n",
       "bNyeTheVRGuy              1.598486e+09     1.598486e+09             1   \n",
       "spec2re                            NaN              NaN             1   \n",
       "\n",
       "                      num_submissions  comment_controversiality  \n",
       "author                                                           \n",
       "brd3001                           NaN                       0.0  \n",
       "lotofmurkamiinthehal              NaN                       0.0  \n",
       "sl_1138                           NaN                       0.0  \n",
       "WaywardTraveller                  NaN                       0.0  \n",
       "fukwhutuheard                     NaN                       0.0  \n",
       "blubburtron                       NaN                       0.0  \n",
       "childish-grambino                 NaN                       0.0  \n",
       "Wakarimasen420                    NaN                       0.0  \n",
       "bNyeTheVRGuy                      1.0                       0.0  \n",
       "spec2re                           NaN                       0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author = pd.DataFrame()\n",
    "print(\"Running...\")\n",
    "for attr, fill in {'text': 'list', 'all_awardings': 'list', 'total_awards_received': 'num', 'score': 'num', 'opinion_score':'num'}.items():\n",
    "    for letter in ['s', 'c']:\n",
    "        \n",
    "        # reformat rows\n",
    "        if fill == 'list':\n",
    "            author_joined[f'{attr}_{letter}'] = author_joined[f'{attr}_{letter}'].fillna(\"\").apply(list)\n",
    "        elif fill == 'num':\n",
    "            author_joined[f'{attr}_{letter}'] = author_joined[f'{attr}_{letter}'].fillna(0)\n",
    "            \n",
    "    # create combined dataframe\n",
    "    author[f'{attr}'] = author_joined[f'{attr}_s'] + author_joined[f'{attr}_c']\n",
    "    if attr == 'opinion_score':\n",
    "        author[f'{attr}'] /= 2\n",
    "    \n",
    "print(\"Successfully combined dataframe!\")\n",
    "\n",
    "# keep relevant attributes\n",
    "aoi = ['first_comment', 'last_comment', \n",
    "       'first_submission', 'last_submission', \n",
    "       'num_comments', 'num_submissions',  \n",
    "       'controversiality']\n",
    "author[aoi] = author_joined[aoi]\n",
    "\n",
    "# modify list of texts to one large string\n",
    "author['text'] = author['text'].progress_apply(lambda x: ' '.join(str(v) for v in x))\n",
    "\n",
    "# rename\n",
    "author = author.rename(columns={'controversiality':'comment_controversiality'})\n",
    "author.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21deb5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9896f832a374f95b62730d5776eebf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11eb1401b804af4950272243192ec3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load stop-words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# add webpages to stopwords\n",
    "stop_words.add('http') \n",
    "stop_words.add('https')\n",
    "\n",
    "# Preprocess the text \n",
    "porter = PorterStemmer()\n",
    "exclusions = {'RT'}\n",
    "\n",
    "# define tokenizing function\n",
    "clean = lambda x: Counter([porter.stem(word_token).lower() for word_token in word_tokenize(x) \\\n",
    "                       if word_token.lower() not in stop_words \\\n",
    "                       and word_token.isalpha() \\\n",
    "                       and word_token not in exclusions])\n",
    "\n",
    "# apply tokenizing to texts - progress_apply for seeing progress bar WHEN running\n",
    "tokens = author['text'].progress_apply(lambda text: clean(text))\n",
    "author['tokens'] = tokens\n",
    "\n",
    "# join tokens to one string\n",
    "author['processed_text'] = author['tokens'].progress_apply(lambda x: ' '.join(str(v) for v in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c6c0ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "author.to_json(DATA_DIR / f'author_opinion_{year}.json.bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac22d7c",
   "metadata": {},
   "source": [
    "## 5) Create ClimateGraph from edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c7d64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "author = pd.read_json(DATA_DIR / f'author_opinion_{year}.json.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8969247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>score</th>\n",
       "      <th>opinion_score</th>\n",
       "      <th>first_comment</th>\n",
       "      <th>last_comment</th>\n",
       "      <th>first_submission</th>\n",
       "      <th>last_submission</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>num_submissions</th>\n",
       "      <th>comment_controversiality</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>warwellian</th>\n",
       "      <td>Thank you for your effort! This gives a cleare...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1579046400</td>\n",
       "      <td>1579046400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'thank': 1, 'effort': 1, 'give': 1, 'clearer'...</td>\n",
       "      <td>thank effort give clearer pictur without nois ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LordYoshi00</th>\n",
       "      <td>I guess you only see that if you're trying to....</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1578182400</td>\n",
       "      <td>1578182400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'guess': 1, 'see': 1, 'tri': 1, 'mayb': 1, 's...</td>\n",
       "      <td>guess see tri mayb said aborigin brought atten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banananuhhh</th>\n",
       "      <td>I think it's actually much worse than you say....</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.272727</td>\n",
       "      <td>1598400000</td>\n",
       "      <td>1605744000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'think': 5, 'actual': 1, 'much': 1, 'wors': 2...</td>\n",
       "      <td>think actual much wors say dem take senat lot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nem48</th>\n",
       "      <td>puppet(s)* It feels good to bash someone else ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1605830400</td>\n",
       "      <td>1605830400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'puppet': 2, 'feel': 1, 'good': 1, 'bash': 1,...</td>\n",
       "      <td>puppet feel good bash someon els tho like knew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>internetguy226</th>\n",
       "      <td>This would require 8 million times more coding...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1583280000</td>\n",
       "      <td>1583280000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>{'would': 1, 'requir': 1, 'million': 1, 'time'...</td>\n",
       "      <td>would requir million time code made</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             text  \\\n",
       "warwellian      Thank you for your effort! This gives a cleare...   \n",
       "LordYoshi00     I guess you only see that if you're trying to....   \n",
       "banananuhhh     I think it's actually much worse than you say....   \n",
       "Nem48           puppet(s)* It feels good to bash someone else ...   \n",
       "internetguy226  This would require 8 million times more coding...   \n",
       "\n",
       "               all_awardings  total_awards_received  score  opinion_score  \\\n",
       "warwellian                []                      0      1       0.000000   \n",
       "LordYoshi00               []                      0      4       0.000000   \n",
       "banananuhhh               []                      0     11      -0.272727   \n",
       "Nem48                     []                      0      2       0.000000   \n",
       "internetguy226            []                      0      1      -0.500000   \n",
       "\n",
       "                first_comment  last_comment  first_submission  \\\n",
       "warwellian         1579046400    1579046400               NaN   \n",
       "LordYoshi00        1578182400    1578182400               NaN   \n",
       "banananuhhh        1598400000    1605744000               NaN   \n",
       "Nem48              1605830400    1605830400               NaN   \n",
       "internetguy226     1583280000    1583280000               NaN   \n",
       "\n",
       "                last_submission  num_comments  num_submissions  \\\n",
       "warwellian                  NaN             1              NaN   \n",
       "LordYoshi00                 NaN             1              NaN   \n",
       "banananuhhh                 NaN            11              NaN   \n",
       "Nem48                       NaN             2              NaN   \n",
       "internetguy226              NaN             1              NaN   \n",
       "\n",
       "                comment_controversiality  \\\n",
       "warwellian                             0   \n",
       "LordYoshi00                            0   \n",
       "banananuhhh                            0   \n",
       "Nem48                                  0   \n",
       "internetguy226                         0   \n",
       "\n",
       "                                                           tokens  \\\n",
       "warwellian      {'thank': 1, 'effort': 1, 'give': 1, 'clearer'...   \n",
       "LordYoshi00     {'guess': 1, 'see': 1, 'tri': 1, 'mayb': 1, 's...   \n",
       "banananuhhh     {'think': 5, 'actual': 1, 'much': 1, 'wors': 2...   \n",
       "Nem48           {'puppet': 2, 'feel': 1, 'good': 1, 'bash': 1,...   \n",
       "internetguy226  {'would': 1, 'requir': 1, 'million': 1, 'time'...   \n",
       "\n",
       "                                                   processed_text  \n",
       "warwellian      thank effort give clearer pictur without nois ...  \n",
       "LordYoshi00     guess see tri mayb said aborigin brought atten...  \n",
       "banananuhhh     think actual much wors say dem take senat lot ...  \n",
       "Nem48           puppet feel good bash someon els tho like knew...  \n",
       "internetguy226                would requir million time code made  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea94826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the weighted edgelist by counting - using score as a randomly picked attributed to obtain a single pd.Series\n",
    "weighted_edgelist = filtered_comments.groupby(by=['author', 'parent_author']).count().score\n",
    "weighted_edgelist = weighted_edgelist.reset_index().rename(columns={'score':'weight'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae243899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>parent_author</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95252</th>\n",
       "      <td>redwolf177</td>\n",
       "      <td>TheNoHeart</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98475</th>\n",
       "      <td>simstim_addict</td>\n",
       "      <td>PragmatistAntithesis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22950</th>\n",
       "      <td>GrievenLeague</td>\n",
       "      <td>Sleaz274</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108708</th>\n",
       "      <td>zeyore</td>\n",
       "      <td>avogadros_number</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85251</th>\n",
       "      <td>lonewolf392</td>\n",
       "      <td>Avenflar</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author         parent_author  weight\n",
       "95252       redwolf177            TheNoHeart       1\n",
       "98475   simstim_addict  PragmatistAntithesis       1\n",
       "22950    GrievenLeague              Sleaz274       1\n",
       "108708          zeyore      avogadros_number       1\n",
       "85251      lonewolf392              Avenflar       2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_edgelist.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58024aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat weighted edgelist to 3-tuples\n",
    "edgelist = list(zip(weighted_edgelist.author, weighted_edgelist.parent_author, weighted_edgelist.weight))\n",
    "\n",
    "# construct graph\n",
    "ClimateGraph = nx.DiGraph()\n",
    "ClimateGraph.add_weighted_edges_from(edgelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40a56cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight': 1}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get weight of edge of first link\n",
    "ClimateGraph.get_edge_data('redwolf177', 'TheNoHeart')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931deb60",
   "metadata": {},
   "source": [
    "## 6) Add node attributes to ClimateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05df161b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16e25c022ad4f82b13e7817b15f30bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for redditor in tqdm(author.index):\n",
    "    meta = {redditor: author.loc[redditor].to_dict()}\n",
    "    nx.set_node_attributes(ClimateGraph, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c3a8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean graph\n",
    "ClimateGraph.remove_edges_from(nx.selfloop_edges(ClimateGraph))\n",
    "\n",
    "# remove nodes that do not have metadata\n",
    "remove_nodes = []\n",
    "for k, v in ClimateGraph.nodes(data=True):\n",
    "    try: \n",
    "        check = v['opinion_score']\n",
    "    except KeyError:\n",
    "        remove_nodes.append(k)\n",
    "\n",
    "Climategraph.remove_nodes_from(remove_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72736157",
   "metadata": {},
   "source": [
    "## 5) Save ClimateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f697291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save graph as json\n",
    "from networkx.readwrite import json_graph\n",
    "import json\n",
    "\n",
    "# specify save location\n",
    "filename = DATA_DIR / f'ClimateGraph_{year}.json'\n",
    "data = json_graph.node_link_data(ClimateGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df3f9665",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(data, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
